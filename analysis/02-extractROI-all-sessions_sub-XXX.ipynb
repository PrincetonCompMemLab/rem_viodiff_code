{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract data from ROIs\n",
    "\n",
    "### Goals of this script\n",
    "1. load normalized BOLD data (from 01-denoise-sesXX_sub-XXX.ipynb)\n",
    "2. apply masks\n",
    "3. save the voxel x TR matrix\n",
    "\n",
    "### For submitting slurm job:\n",
    "- approximate time to run for one subject: 1 hr\n",
    "\n",
    "#### 9/27/22 Modification:\n",
    "- intersect brain mask and ROI mask to remove any voxels with no signal from the ROI mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub='sub-XXX'\n",
    "\n",
    "# if using trimmed 'raw' patterns\n",
    "n_trunc_beginning=9 #Number of volumes to trim/truncate\n",
    "n_trunc_end=5\n",
    "\n",
    "version='v4' #for hippocampal masks\n",
    "binarization_thresh='50' #for hippocampal masks\n",
    "\n",
    "rsa_ROIs = ['bilateral_oc-temp_v2', 'bilateral_CA2+3+DG_1.5mm', 'left_CA2+3+DG_1.5mm', 'right_CA2+3+DG_1.5mm', \n",
    "            'bilateral_CA1_1.5mm', 'left_CA1_1.5mm', 'right_CA1_1.5mm',\n",
    "            'bilateral_CA2+3_1.5mm', 'left_CA2+3_1.5mm', 'right_CA2+3_1.5mm',\n",
    "            'bilateral_DG_1.5mm', 'left_DG_1.5mm', 'right_DG_1.5mm']\n",
    "\n",
    "make_intersected_mask = 0 #1 to intersect brain mask with ROI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import sys \n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import nilearn\n",
    "from nilearn.input_data import NiftiMasker,  MultiNiftiMasker\n",
    "from nilearn.masking import intersect_masks\n",
    "from nilearn import image\n",
    "from nilearn import plotting\n",
    "import scipy.io\n",
    "from scipy import stats\n",
    "import os\n",
    "from os.path import join, exists, split\n",
    "import pickle \n",
    "import time\n",
    "from pathlib import Path\n",
    "from shutil import copyfile\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline \n",
    "%autosave 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    "print('The python version is {}.'.format(python_version()))\n",
    "print('The numpy version is {}.'.format(np.__version__))\n",
    "print('The nilearn version is {}.'.format(nilearn.__version__))\n",
    "print('The nibabel version is {}.'.format(nib.__version__))\n",
    "print('The seaborn version is {}.'.format(sns.__version__))\n",
    "\n",
    "assert python_version()== '3.7.6'\n",
    "assert nilearn.__version__=='0.6.2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set printing precision\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "\n",
    "# load some helper functions\n",
    "sys.path.insert(0, '/path/to/code/directory')\n",
    "import svd_utils\n",
    "from svd_utils import load_svd_stim_labels, load_svd_epi_data, shift_timing, label2TR\n",
    "\n",
    "# load some constants\n",
    "from svd_utils import svd_dir, svd_bids_dir, svd_TR, svd_hrf_lag, run_names, n_runs, TRs_run\n",
    "shift_size = int(svd_hrf_lag / svd_TR) # Convert the shift into TRs\n",
    "\n",
    "deriv_dir=svd_bids_dir + 'derivatives/'\n",
    "anat_dir=deriv_dir + 'deface/'\n",
    "firstlevel_dir=deriv_dir + 'firstlevel/%s/' % sub\n",
    "\n",
    "print('ROIs = %s' % (rsa_ROIs))\n",
    "print('')\n",
    "print('%d volumes trimmed from beginning of each run' % (n_trunc_beginning))\n",
    "print('%d volumes trimmed from end of each run' % (n_trunc_end))\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Where do you want to save the masked data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = deriv_dir + 'path/to/output'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Where are hippocampal masks located? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_fold_hipp=firstlevel_dir + 'rois_ashs/t1space_%s/threshold-%s/' % (version,binarization_thresh)\n",
    "print('masking data using masks from %s' %mask_fold_hipp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Where are non-hippocampal masks located? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_fold=deriv_dir + 'firstlevel/%s/masks/' %sub\n",
    "print('masking data using masks from %s' %mask_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a function to load the mask data\n",
    "def load_svd_mask(ROI_name, sub):\n",
    "    \"\"\"Load the mask for the svd data \n",
    "    Parameters\n",
    "    ----------\n",
    "    ROI_name: string\n",
    "    sub: string \n",
    "    \n",
    "    Return\n",
    "    ----------\n",
    "    the requested mask\n",
    "    \"\"\"    \n",
    "    # load the mask\n",
    "    maskfile = (mask_fold + sub + \"_%s.nii.gz\" % (ROI_name))\n",
    "    mask = nib.load(maskfile)\n",
    "    print(\"Loaded %s mask\" % (ROI_name))\n",
    "    return mask\n",
    "\n",
    "def mask_data(epi_data, mask): \n",
    "    \"\"\"mask the input data with the input mask \n",
    "    Parameters\n",
    "    ----------\n",
    "    epi_data\n",
    "    mask\n",
    "    \n",
    "    Return\n",
    "    ----------\n",
    "    masked data\n",
    "    \"\"\"    \n",
    "    #check that masks and BOLD data match\n",
    "    assert mask.shape==epi_data.shape[:3] \n",
    "    assert mask.header.get_zooms()==epi_data.header.get_zooms()[0:3] #resolution\n",
    "    assert mask.affine.all()==epi_data.affine.all() #check that affines match\n",
    "    print('mask shape:', mask.shape, 'dimensions:', mask.header.get_zooms())\n",
    "    print('mask affine:')\n",
    "    print(mask.affine)\n",
    "    \n",
    "    nifti_masker = NiftiMasker(mask_img=mask)\n",
    "    epi_masked_data = nifti_masker.fit_transform(epi_data);\n",
    "    return epi_masked_data\n",
    "\n",
    "def load_svd_masked_data(directory, subject_name, mask_list):\n",
    "    masked_data_all = [0] * len(mask_list)\n",
    "\n",
    "    # Cycle through the masks\n",
    "    for mask_counter in range(len(mask_list)):\n",
    "        # load the mask for the corresponding ROI\n",
    "        this_mask = mask_list[mask_counter]\n",
    "        mask = load_svd_mask(mask_list[mask_counter], subject_name)\n",
    "        \n",
    "        # # plot mask overlayed on subject's T1\n",
    "        #plot_roi(mask, bg_img=t1_img, title=this_mask)\n",
    "        \n",
    "        # mask the data \n",
    "        print('extracting masked data for %s' %(this_mask))\n",
    "        epi_masked_data = mask_data(epi_data, mask)\n",
    "        epi_masked_data = np.transpose(epi_masked_data)\n",
    "        \n",
    "        # Check the dimensionality of the data\n",
    "        print('voxel by TR matrix - shape: ', epi_masked_data.shape)\n",
    "        print('')\n",
    "        \n",
    "        masked_data_all[mask_counter] = epi_masked_data\n",
    "        \n",
    "    return masked_data_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure that only voxels included in brain mask are included in oc-temp mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: ROI here is hardcoded as bilateral_oc-temp\n",
    "if make_intersected_mask == 1:\n",
    "    mask_imgs=[]\n",
    "\n",
    "    brain_mask = mask_fold + sub + '_ses-01_brain.nii.gz'\n",
    "    roi_mask = mask_fold + sub + '_bilateral_oc-temp.nii.gz'\n",
    "    brain_img = nib.load(brain_mask)\n",
    "    roi_img = nib.load(roi_mask)\n",
    "    print('brain image:', brain_img.shape)\n",
    "    print(brain_img.affine)\n",
    "    print('roi:', roi_img.shape)\n",
    "    print(roi_img.affine)\n",
    "\n",
    "    mask_imgs.append(brain_mask)\n",
    "    mask_imgs.append(roi_mask)\n",
    "\n",
    "    # intersect masks    \n",
    "    new_mask=intersect_masks(mask_imgs, threshold=1, connected=False)\n",
    "    print('new mask:', new_mask.shape)\n",
    "    print(new_mask.affine)\n",
    "    \n",
    "    # Save the mask\n",
    "    output_name = mask_fold + sub + '_bilateral_oc-temp_v2.nii.gz'\n",
    "    print('Save intersected mask:', output_name)\n",
    "    print('')\n",
    "\n",
    "    dimsize=new_mask.header.get_zooms()\n",
    "    affine_mat = new_mask.affine\n",
    "    print('Mask dimensions:', dimsize)\n",
    "    print('')\n",
    "\n",
    "    hdr = new_mask.header  # get a handle for the .nii file's header\n",
    "    hdr.set_zooms((dimsize[0], dimsize[1], dimsize[2]))\n",
    "    nib.save(new_mask, output_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load fMRI data and apply masks\n",
    "\n",
    "### LOCALIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute=0 #1 to run, 0 to skip\n",
    "ses='ses-00'\n",
    "task='localizer'\n",
    "task_index = run_names.index(task)\n",
    "n_runs_task = n_runs[task_index]\n",
    "TRs_run_task=TRs_run[task_index]-n_trunc_beginning-n_trunc_end #if data are already trimmed, update TRs_run\n",
    "\n",
    "print('LIST OF TASKS:', run_names)\n",
    "print('task index:', task_index)\n",
    "print('')\n",
    "print('TR = %s seconds' % (svd_TR))\n",
    "print('%d volumes trimmed from beginning of each run' % (n_trunc_beginning))\n",
    "print('%d volumes trimmed from end of each run' % (n_trunc_end))\n",
    "print('')\n",
    "print('Number of %s runs = %s and TRs per run = %s' % (task, n_runs_task, TRs_run[task_index]))\n",
    "print('TRs per %s run after trimming = %s' % (task,TRs_run_task))\n",
    "print('')\n",
    "print('available ROIs: ', rsa_ROIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if execute==1:\n",
    "    \n",
    "    # load normalized BOLD data\n",
    "    epi_data=[]\n",
    "    epi_in = (firstlevel_dir  + ses + \"/%s_%s_task-%s_run-ALL_space-T1w_desc-preproc_bold_trim%dand%dTRs_normalized.nii.gz\" % (sub, ses, task, n_trunc_beginning, n_trunc_end))\n",
    "    epi_data = nib.load(epi_in)\n",
    "    assert epi_data.shape[3]==n_runs_task*TRs_run_task\n",
    "    print(\"Loading data from %s\" % (epi_in))\n",
    "    print('')\n",
    "    print('epi_data shape: ', epi_data.shape, 'dimensions:', epi_data.header.get_zooms())\n",
    "    print('epi_data affine:')\n",
    "    print(epi_data.affine)\n",
    "    print('')\n",
    "    \n",
    "    # Extract voxels for each ROI using NiftiMasker\n",
    "    masked_data_all = load_svd_masked_data(mask_fold, sub, rsa_ROIs)\n",
    "    \n",
    "    # Plot data (first 250 voxels only)\n",
    "    for mask_counter in range(len(rsa_ROIs)):\n",
    "        this_mask = rsa_ROIs[mask_counter]\n",
    "        plt.figure(figsize=(20,10))\n",
    "        plt.matshow(masked_data_all[mask_counter][:250,:]) #[voxel,time]\n",
    "        plt.title(this_mask)\n",
    "    \n",
    "    # Save data\n",
    "    for mask_counter in range(len(rsa_ROIs)):\n",
    "        this_mask = rsa_ROIs[mask_counter]\n",
    "        mat_out = out_dir + '%s_task-%s_run-ALL_space-T1w_trim%dand%dTRs_mask-%s' % (sub, task, n_trunc_beginning, n_trunc_end, this_mask)\n",
    "        print('saving to file: ', mat_out)\n",
    "        print('')\n",
    "        scipy.io.savemat(mat_out, mdict={'data': masked_data_all[mask_counter]})\n",
    "\n",
    "    print('Saving complete')\n",
    "\n",
    "else:\n",
    "    print('Skipping %s task' % (task))     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STUDY AND POSTSCENES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute=0 #1 to run, 0 to skip\n",
    "ses='ses-01'\n",
    "task='study'\n",
    "task2='postScenes'\n",
    "task_index = run_names.index(task)\n",
    "task2_index = run_names.index(task2)\n",
    "n_runs_task = n_runs[task_index]\n",
    "n_runs_task2 = n_runs[task2_index]\n",
    "n_runs_total = n_runs_task + n_runs_task2\n",
    "TRs_run_task=TRs_run[task_index]-n_trunc_beginning-n_trunc_end #if data are already trimmed, update TRs_run\n",
    "TRs_run_task2=TRs_run[task2_index]-n_trunc_beginning-n_trunc_end\n",
    "\n",
    "print('LIST OF TASKS:', run_names)\n",
    "print('task index:', task_index)\n",
    "print('task index:', task2_index)\n",
    "print('')\n",
    "print('TR = %s seconds' % (svd_TR))\n",
    "print('%d volumes trimmed from beginning of each run' % (n_trunc_beginning))\n",
    "print('%d volumes trimmed from end of each run' % (n_trunc_end))\n",
    "print('')\n",
    "print('Number of %s runs = %s and TRs per run = %s' % (task, n_runs_task, TRs_run[task_index]))\n",
    "print('TRs per %s run after trimming = %s' % (task, TRs_run_task))\n",
    "print('Number of %s runs = %s and TRs per run = %s' % (task2, n_runs_task2, TRs_run[task2_index]))\n",
    "print('TRs per %s run after trimming = %s' % (task2, TRs_run_task2))\n",
    "print('')\n",
    "print('available ROIs: ', rsa_ROIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if execute==1:\n",
    "    \n",
    "    # load normalized BOLD data\n",
    "    epi_data=[]\n",
    "    epi_in = (firstlevel_dir  + ses + \"/%s_ses-01and02_task-study-and-postscenes_run-ALL_space-T1w_desc-preproc_bold_trim%dand%dTRs_normalized.nii.gz\" % (sub, n_trunc_beginning, n_trunc_end))\n",
    "    epi_data = nib.load(epi_in)\n",
    "    assert epi_data.shape[3]==(n_runs_task*TRs_run_task)+(n_runs_task2*TRs_run_task2)\n",
    "    print(\"Loading data from %s\" % (epi_in))\n",
    "    print('')\n",
    "    print('epi_data shape: ', epi_data.shape, 'dimensions:', epi_data.header.get_zooms())\n",
    "    print('epi_data affine:')\n",
    "    print(epi_data.affine)\n",
    "    print('')\n",
    "    \n",
    "    # Extract voxels for each ROI using NiftiMasker\n",
    "    masked_data_all = load_svd_masked_data(mask_fold, sub, rsa_ROIs)\n",
    "    \n",
    "    # Plot data (first 250 voxels only)\n",
    "    for mask_counter in range(len(rsa_ROIs)):\n",
    "        this_mask = rsa_ROIs[mask_counter]\n",
    "        plt.figure(figsize=(20,10))\n",
    "        plt.matshow(masked_data_all[mask_counter][:250,:]) #[voxel,time]\n",
    "        plt.title(this_mask)\n",
    "    \n",
    "    # Save data\n",
    "    for mask_counter in range(len(rsa_ROIs)):\n",
    "        this_mask = rsa_ROIs[mask_counter]\n",
    "        mat_out = out_dir + '%s_task-study-and-postscenes_run-ALL_space-T1w_trim%dand%dTRs_mask-%s' % (sub, n_trunc_beginning, n_trunc_end, this_mask)\n",
    "        print('saving to file: ', mat_out)\n",
    "        print('')\n",
    "        scipy.io.savemat(mat_out, mdict={'data': masked_data_all[mask_counter]})\n",
    "\n",
    "    print('Saving complete')\n",
    "\n",
    "else:\n",
    "    print('Skipping %s task' % ('study-and-postscenes'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POSTSCENES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute=0 #1 to run, 0 to skip\n",
    "ses='ses-02'\n",
    "task='postScenes'\n",
    "task_index = run_names.index(task)\n",
    "n_runs_task = n_runs[task_index]\n",
    "TRs_run_task=TRs_run[task_index]-n_trunc_beginning-n_trunc_end #if data are already trimmed, update TRs_run\n",
    "\n",
    "print('LIST OF TASKS:', run_names)\n",
    "print('task index:', task_index)\n",
    "print('')\n",
    "print('TR = %s seconds' % (svd_TR))\n",
    "print('%d volumes trimmed from beginning of each run' % (n_trunc_beginning))\n",
    "print('%d volumes trimmed from end of each run' % (n_trunc_end))\n",
    "print('')\n",
    "print('Number of %s runs = %s and TRs per run = %s' % (task, n_runs_task, TRs_run[task_index]))\n",
    "print('TRs per %s run after trimming = %s' % (task,TRs_run_task))\n",
    "print('')\n",
    "print('available ROIs: ', rsa_ROIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if execute==1:\n",
    "    \n",
    "    task='postscenes'\n",
    "    # load normalized BOLD data\n",
    "    epi_data=[]\n",
    "    epi_in = (firstlevel_dir  + ses + \"/%s_%s_task-%s_run-01_space-T1w_desc-preproc_bold_trim%dand%dTRs_normalized.nii.gz\" % (sub, ses, task, n_trunc_beginning, n_trunc_end))\n",
    "    epi_data = nib.load(epi_in)\n",
    "    assert epi_data.shape[3]==n_runs_task*TRs_run_task\n",
    "    print(\"Loading data from %s\" % (epi_in))\n",
    "    print('')\n",
    "    print('epi_data shape: ', epi_data.shape, 'dimensions:', epi_data.header.get_zooms())\n",
    "    print('epi_data affine:')\n",
    "    print(epi_data.affine)\n",
    "    print('')\n",
    "    \n",
    "    # Extract voxels for each ROI using NiftiMasker\n",
    "    masked_data_all = load_svd_masked_data(mask_fold, sub, rsa_ROIs)\n",
    "    \n",
    "    # Plot data (first 250 voxels only)\n",
    "    for mask_counter in range(len(rsa_ROIs)):\n",
    "        this_mask = rsa_ROIs[mask_counter]\n",
    "        plt.figure(figsize=(20,10))\n",
    "        plt.matshow(masked_data_all[mask_counter][:250,:]) #[voxel,time]\n",
    "        plt.title(this_mask)\n",
    "    \n",
    "    # Save data\n",
    "    for mask_counter in range(len(rsa_ROIs)):\n",
    "        this_mask = rsa_ROIs[mask_counter]\n",
    "        mat_out = out_dir + '%s_task-%s_run-01_space-T1w_trim%dand%dTRs_mask-%s' % (sub, task, n_trunc_beginning, n_trunc_end, this_mask)\n",
    "        print('saving to file: ', mat_out)\n",
    "        print('')\n",
    "        scipy.io.savemat(mat_out, mdict={'data': masked_data_all[mask_counter]})\n",
    "\n",
    "    print('Saving complete')\n",
    "\n",
    "else:\n",
    "    print('Skipping %s task' % (task))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POSTFACES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute=0 #1 to run, 0 to skip\n",
    "ses='ses-02'\n",
    "task='postFaces'\n",
    "task_index = run_names.index(task)\n",
    "n_runs_task = n_runs[task_index]\n",
    "TRs_run_task=TRs_run[task_index]-n_trunc_beginning-n_trunc_end #if data are already trimmed, update TRs_run\n",
    "\n",
    "print('LIST OF TASKS:', run_names)\n",
    "print('task index:', task_index)\n",
    "print('')\n",
    "print('TR = %s seconds' % (svd_TR))\n",
    "print('%d volumes trimmed from beginning of each run' % (n_trunc_beginning))\n",
    "print('%d volumes trimmed from end of each run' % (n_trunc_end))\n",
    "print('')\n",
    "print('Number of %s runs = %s and TRs per run = %s' % (task, n_runs_task, TRs_run[task_index]))\n",
    "print('TRs per %s run after trimming = %s' % (task,TRs_run_task))\n",
    "print('')\n",
    "print('available ROIs: ', rsa_ROIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if execute==1:\n",
    "    \n",
    "    task='postfaces'\n",
    "    # load normalized BOLD data\n",
    "    epi_data=[]\n",
    "    epi_in = (firstlevel_dir  + ses + \"/%s_%s_task-%s_run-01_space-T1w_desc-preproc_bold_trim%dand%dTRs_normalized.nii.gz\" % (sub, ses, task, n_trunc_beginning, n_trunc_end))\n",
    "    epi_data = nib.load(epi_in)\n",
    "    assert epi_data.shape[3]==n_runs_task*TRs_run_task\n",
    "    print(\"Loading data from %s\" % (epi_in))\n",
    "    print('')\n",
    "    print('epi_data shape: ', epi_data.shape, 'dimensions:', epi_data.header.get_zooms())\n",
    "    print('epi_data affine:')\n",
    "    print(epi_data.affine)\n",
    "    print('')\n",
    "    \n",
    "    # Extract voxels for each ROI using NiftiMasker\n",
    "    masked_data_all = load_svd_masked_data(mask_fold, sub, rsa_ROIs)\n",
    "    \n",
    "    # Plot data (first 250 voxels only)\n",
    "    for mask_counter in range(len(rsa_ROIs)):\n",
    "        this_mask = rsa_ROIs[mask_counter]\n",
    "        plt.figure(figsize=(20,10))\n",
    "        plt.matshow(masked_data_all[mask_counter][:250,:]) #[voxel,time]\n",
    "        plt.title(this_mask)\n",
    "    \n",
    "    # Save data\n",
    "    for mask_counter in range(len(rsa_ROIs)):\n",
    "        this_mask = rsa_ROIs[mask_counter]\n",
    "        mat_out = out_dir + '%s_task-%s_run-01_space-T1w_trim%dand%dTRs_mask-%s' % (sub, task, n_trunc_beginning, n_trunc_end, this_mask)\n",
    "        print('saving to file: ', mat_out)\n",
    "        print('')\n",
    "        scipy.io.savemat(mat_out, mdict={'data': masked_data_all[mask_counter]})\n",
    "\n",
    "    print('Saving complete')\n",
    "\n",
    "else:\n",
    "    print('Skipping %s task' % (task))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REWARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute=0 #1 to run, 0 to skip\n",
    "ses='ses-02'\n",
    "task='reward'\n",
    "task_index = run_names.index(task)\n",
    "n_runs_task = n_runs[task_index]\n",
    "TRs_run_task=TRs_run[task_index]-n_trunc_beginning-n_trunc_end #if data are already trimmed, update TRs_run\n",
    "\n",
    "print('LIST OF TASKS:', run_names)\n",
    "print('task index:', task_index)\n",
    "print('')\n",
    "print('TR = %s seconds' % (svd_TR))\n",
    "print('%d volumes trimmed from beginning of each run' % (n_trunc_beginning))\n",
    "print('%d volumes trimmed from end of each run' % (n_trunc_end))\n",
    "print('')\n",
    "print('Number of %s runs = %s and TRs per run = %s' % (task, n_runs_task, TRs_run[task_index]))\n",
    "print('TRs per %s run after trimming = %s' % (task,TRs_run_task))\n",
    "print('')\n",
    "print('available ROIs: ', rsa_ROIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if execute==1:\n",
    "    \n",
    "    # load normalized BOLD data\n",
    "    epi_data=[]\n",
    "    epi_in = (firstlevel_dir  + ses + \"/%s_%s_task-%s_run-ALL_space-T1w_desc-preproc_bold_trim%dand%dTRs_normalized.nii.gz\" % (sub, ses, task, n_trunc_beginning, n_trunc_end))\n",
    "    epi_data = nib.load(epi_in)\n",
    "    assert epi_data.shape[3]==n_runs_task*TRs_run_task\n",
    "    print(\"Loading data from %s\" % (epi_in))\n",
    "    print('')\n",
    "    print('epi_data shape: ', epi_data.shape, 'dimensions:', epi_data.header.get_zooms())\n",
    "    print('epi_data affine:')\n",
    "    print(epi_data.affine)\n",
    "    print('')\n",
    "    \n",
    "    # Extract voxels for each ROI using NiftiMasker\n",
    "    masked_data_all = load_svd_masked_data(mask_fold, sub, rsa_ROIs)\n",
    "    \n",
    "    # Plot data (first 250 voxels only)\n",
    "    for mask_counter in range(len(rsa_ROIs)):\n",
    "        this_mask = rsa_ROIs[mask_counter]\n",
    "        plt.figure(figsize=(20,10))\n",
    "        plt.matshow(masked_data_all[mask_counter][:250,:]) #[voxel,time]\n",
    "        plt.title(this_mask)\n",
    "    \n",
    "    # Save data\n",
    "    for mask_counter in range(len(rsa_ROIs)):\n",
    "        this_mask = rsa_ROIs[mask_counter]\n",
    "        mat_out = out_dir + '%s_task-%s_run-ALL_space-T1w_trim%dand%dTRs_mask-%s' % (sub, task, n_trunc_beginning, n_trunc_end, this_mask)\n",
    "        print('saving to file: ', mat_out)\n",
    "        print('')\n",
    "        scipy.io.savemat(mat_out, mdict={'data': masked_data_all[mask_counter]})\n",
    "\n",
    "    print('Saving complete')\n",
    "\n",
    "else:\n",
    "    print('Skipping %s task' % (task))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FAMILIARIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute=0 #1 to run, 0 to skip\n",
    "ses='ses-02'\n",
    "task='familiarization'\n",
    "task_index = run_names.index(task)\n",
    "n_runs_task = n_runs[task_index]\n",
    "TRs_run_task=TRs_run[task_index]-n_trunc_beginning-n_trunc_end #if data are already trimmed, update TRs_run\n",
    "\n",
    "print('LIST OF TASKS:', run_names)\n",
    "print('task index:', task_index)\n",
    "print('')\n",
    "print('TR = %s seconds' % (svd_TR))\n",
    "print('%d volumes trimmed from beginning of each run' % (n_trunc_beginning))\n",
    "print('%d volumes trimmed from end of each run' % (n_trunc_end))\n",
    "print('')\n",
    "print('Number of %s runs = %s and TRs per run = %s' % (task, n_runs_task, TRs_run[task_index]))\n",
    "print('TRs per %s run after trimming = %s' % (task,TRs_run_task))\n",
    "print('')\n",
    "print('available ROIs: ', rsa_ROIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if execute==1:  \n",
    "    \n",
    "    # load normalized BOLD data\n",
    "    epi_data=[]\n",
    "    epi_in = (firstlevel_dir  + ses + \"/%s_%s_task-%s_run-ALL_space-T1w_desc-preproc_bold_trim%dand%dTRs_normalized.nii.gz\" % (sub, ses, task, n_trunc_beginning, n_trunc_end))\n",
    "    epi_data = nib.load(epi_in)\n",
    "    assert epi_data.shape[3]==n_runs_task*TRs_run_task\n",
    "    print(\"Loading data from %s\" % (epi_in))\n",
    "    print('')\n",
    "    print('epi_data shape: ', epi_data.shape, 'dimensions:', epi_data.header.get_zooms())\n",
    "    print('epi_data affine:')\n",
    "    print(epi_data.affine)\n",
    "    print('')\n",
    "    \n",
    "    # Extract voxels for each ROI using NiftiMasker\n",
    "    masked_data_all = load_svd_masked_data(mask_fold, sub, rsa_ROIs)\n",
    "    \n",
    "    # Plot data (first 250 voxels only)\n",
    "    for mask_counter in range(len(rsa_ROIs)):\n",
    "        this_mask = rsa_ROIs[mask_counter]\n",
    "        plt.figure(figsize=(20,10))\n",
    "        plt.matshow(masked_data_all[mask_counter][:250,:]) #[voxel,time]\n",
    "        plt.title(this_mask)\n",
    "    \n",
    "    # Save data\n",
    "    for mask_counter in range(len(rsa_ROIs)):\n",
    "        this_mask = rsa_ROIs[mask_counter]\n",
    "        mat_out = out_dir + '%s_task-%s_run-ALL_space-T1w_trim%dand%dTRs_mask-%s' % (sub, task, n_trunc_beginning, n_trunc_end, this_mask)\n",
    "        print('saving to file: ', mat_out)\n",
    "        print('')\n",
    "        scipy.io.savemat(mat_out, mdict={'data': masked_data_all[mask_counter]})\n",
    "\n",
    "    print('Saving complete')\n",
    "\n",
    "else:\n",
    "    print('Skipping %s task' % (task))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
